# ğŸ§  Clickstream Recommender System (Session-Based)

This project builds a streaming recommendation system using simulated clickstream data. It processes real-time product interaction events and trains a collaborative filtering model to recommend products based on session behavior.

---

## âš™ï¸ Tech Stack

| Layer         | Tool/Service                             |
|---------------|------------------------------------------|
| Ingestion     | Kafka (Confluent Cloud) + Python Producer |
| Processing    | Spark Structured Streaming on Databricks |
| Storage       | Azure Data Lake Gen2 (Delta format)      |
| Recommendation| ALS (Spark MLlib)                        |
| Dashboard     | Streamlit (local)                        |

---

## ğŸ§± Project Structure

```
03-clickstream-recommender/
â”œâ”€â”€ producer/
â”‚   â””â”€â”€ clickstream_producer.py
â”œâ”€â”€ databricks/
â”‚   â”œâ”€â”€ bronze_layer.py
â”‚   â”œâ”€â”€ silver_layer.py
â”‚   â””â”€â”€ gold_layer_modeling.py
â”œâ”€â”€ streamlit_dashboard/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ architecture_diagram.png
â”‚   â””â”€â”€ flow.md
â”œâ”€â”€ sample_data/
â”‚   â””â”€â”€ sample_clicks.json
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š Features Implemented

- Real-time ingestion of clickstream data via Kafka
- Structured Bronze â†’ Silver pipeline with timestamped events
- Gold layer with session aggregations (duration, event counts)
- ALS model trained using session-item matrix
- Local Streamlit app to show top recommendations by session

---

## ğŸ§­ Architecture

![Architecture Diagram](architecture/architecture_diagram.png)

---

## ğŸ”„ Pipeline Flow

1. User click events (views, add to cart, purchase) are simulated using a Kafka producer.
2. Spark reads and stores them in Bronze Delta Lake on Azure.
3. Silver layer cleans data, extracts sessions and events.
4. Gold layer builds user-item interaction matrix, trains ALS model.
5. Streamlit shows top-N product recommendations per user session.

---

## ğŸ§ª How to Run

### 1. Kafka Producer (Local)

```bash
cd producer/
python clickstream_producer.py
```

### 2. Databricks ETL Pipeline

Run notebooks in order:
- `bronze_layer.py`
- `silver_layer.py`
- `gold_layer_modeling.py` (includes ALS model)

### 3. Streamlit Recommendation Dashboard

```bash
cd streamlit_dashboard/
streamlit run app.py
```

---

## ğŸ” Authentication

| Component   | Access Method           |
|------------|--------------------------|
| Kafka       | SASL_SSL + API key/secret |
| Azure Blob  | SAS Token (read access)  |
| Databricks  | Workspace-connected notebooks |

---

## ğŸ“Œ Sample Click Event

```json
{
  "timestamp": "2025-07-13T18:42:10Z",
  "session_id": "sess_102",
  "user_id": "user_12",
  "item_id": "prod_88",
  "event_type": "view"
}
```

---

## ğŸ“ˆ Dashboard Outputs

- Recommended products per session
- Most viewed products
- Top active sessions
- Session engagement metrics

---

## ğŸ‘¤ Author

Built by [Your Name](https://linkedin.com/in/your-profile)

---

## ğŸ“ Related Projects

- [01: Real-Time User Interaction Pipeline](../01-user-interaction-pipeline/)
- [02: YouTube Sentiment Pipeline](../02-youtube-sentiment-pipeline/)
- [04: Streaming Log Analytics](../04-streaming-log-analytics/)